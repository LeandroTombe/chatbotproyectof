# ğŸ¤– ChatBot RAG - Sistema de Chat con RecuperaciÃ³n de Documentos

<div align="center">

![Python](https://img.shields.io/badge/Python-3.12-blue.svg)
![Ollama](https://img.shields.io/badge/Ollama-LLM-green.svg)
![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

**Sistema de chat inteligente que responde preguntas basÃ¡ndose exclusivamente en tus documentos**

[CaracterÃ­sticas](#-caracterÃ­sticas) â€¢
[InstalaciÃ³n](#-instalaciÃ³n) â€¢
[Uso](#-uso) â€¢
[Docker](#-docker) â€¢
[DocumentaciÃ³n](#-documentaciÃ³n)

</div>

---

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n Ejecutiva](#-descripciÃ³n-ejecutiva)
- [DescripciÃ³n TÃ©cnica](#-descripciÃ³n-tÃ©cnica)
- [CÃ³mo Funciona en Simple](#-cÃ³mo-funciona-en-simple)
- [QuÃ© Problema Resuelve](#-quÃ©-problema-resuelve)
- [Por QuÃ© Es una SoluciÃ³n Profesional](#-por-quÃ©-es-una-soluciÃ³n-profesional-y-segura)
- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [CÃ³mo Funciona](#-cÃ³mo-funciona)
- [Arquitectura](#-arquitectura)
- [TecnologÃ­as](#-tecnologÃ­as)
- [Requisitos](#-requisitos)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [ConfiguraciÃ³n](#-configuraciÃ³n)
- [Uso](#-uso)
- [Docker](#-docker)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Testing](#-testing)
- [DocumentaciÃ³n Adicional](#-documentaciÃ³n-adicional)
- [ContribuciÃ³n](#-contribuciÃ³n)
- [Licencia](#-licencia)

---

## ï¿½ DescripciÃ³n Ejecutiva

**ChatBot RAG** es un asistente de inteligencia artificial que responde preguntas usando **Ãºnicamente la informaciÃ³n de los documentos internos de la organizaciÃ³n**. A diferencia de herramientas como ChatGPT, no tiene acceso a internet ni inventa respuestas: todo lo que dice proviene textualmente de los archivos que se le proporcionan, citando siempre la fuente exacta. Funciona de forma completamente privada dentro de la red corporativa, sin enviar ningÃºn dato al exterior. Es configurable, escalable y estÃ¡ construido con estÃ¡ndares de ingenierÃ­a de software profesional, garantizando mantenibilidad a largo plazo. Puede desplegarse en cualquier servidor interno o nube privada, y su arquitectura modular permite incorporar nuevos tipos de documentos o modelos de IA sin reescribir el sistema.

âœ… **Solo responde con informaciÃ³n de tus documentos**  
âœ… **Cita las fuentes** de cada respuesta  
âœ… **Detecta preguntas maliciosas** con filtros de seguridad  
âœ… **Funciona 100% offline** â€” sin dependencias externas  
âœ… **Mantiene contexto** de la conversaciÃ³n  
âœ… **Se actualiza automÃ¡ticamente** al agregar nuevos PDFs

**Casos de uso ideales**: AtenciÃ³n al cliente, documentaciÃ³n interna, base de conocimientos empresarial, asistentes educativos, soporte tÃ©cnico automatizado.

---

## ğŸ› ï¸ DescripciÃ³n TÃ©cnica

El sistema implementa una arquitectura **RAG (Retrieval-Augmented Generation)** con separaciÃ³n estricta de responsabilidades:

**Pipeline de ingesta (ETL):**
- Carga PDFs mediante loaders intercambiables (`Factory Pattern`)
- Divide el texto en fragmentos con overlap configurable (`TextChunker`)
- Genera embeddings semÃ¡nticos con `intfloat/multilingual-e5` vÃ­a HuggingFace
- Persiste vectores en **ChromaDB** con detecciÃ³n de duplicados por hash determinÃ­stico
- Vigila carpetas automÃ¡ticamente con `watchdog` para ingesta en tiempo real
- Al arrancar, indexa solo los documentos nuevos â€” salta los ya procesados

**Pipeline de consulta:**
- BÃºsqueda por similitud coseno con soporte a **MMR** (mÃ¡xima marginal relevancia) y bÃºsqueda expandida
- Filtro de relevancia configurable (`min_score`)
- ValidaciÃ³n de seguridad en doble capa: 44+ palabras clave + 7 patrones regex contra prompt injection

**Capa LLM:**
- Cliente Ollama con interfaz abstracta (`Strategy Pattern`) â€” soporta `llama3.2`, `mistral`, `phi`, `codellama`
- Modo estricto: el modelo **no puede responder fuera del contexto recuperado**
- Historial de conversaciÃ³n con ventana de contexto gestionada

**Calidad de cÃ³digo:**
- `BaseSettings` Pydantic para configuraciÃ³n tipada vÃ­a `.env`
- 290+ tests con pytest (unitarios + integraciÃ³n)
- Type hints completos, validados con mypy
- ContainerizaciÃ³n completa con Docker Compose

---

## ğŸ’¡ CÃ³mo Funciona en Simple

ImaginÃ¡ que tenÃ©s un empleado nuevo muy inteligente. El primer dÃ­a le das a leer todos los manuales, reglamentos y documentos de la empresa. Ã‰l los lee, los memoriza y los organiza internamente de una forma que le permite encontrar informaciÃ³n en segundos.

Cuando alguien le hace una pregunta, **no inventa nada**: busca en su memoria quÃ© parte de quÃ© documento responde mejor esa pregunta y te da la respuesta citando exactamente de dÃ³nde la sacÃ³. Si no sabe algo porque no estÃ¡ en ningÃºn documento, lo dice directamente.

AdemÃ¡s, este empleado **nunca sale de la oficina**: toda su memoria y todo su conocimiento estÃ¡ guardado dentro de la empresa, sin depender de internet ni de servidores externos. Y si alguien intenta confundirlo con preguntas maliciosas o engaÃ±osas, tiene entrenamiento para detectarlas y no responderlas.

---

## ğŸ¯ QuÃ© Problema Resuelve

Las empresas acumulan enormes volÃºmenes de documentaciÃ³n interna (manuales, polÃ­ticas, contratos, FAQs, reglamentos) que el personal no puede consultar fÃ¡cilmente. Buscar informaciÃ³n relevante toma tiempo, genera errores y depende de que la persona correcta estÃ© disponible.

| Chatbot comÃºn | Este sistema |
|---|---|
| Responde con conocimiento general de internet | Responde **solo** con los documentos de la empresa |
| Puede inventar informaciÃ³n (*alucinaciones*) | Solo habla si la informaciÃ³n estÃ¡ en los documentos |
| EnvÃ­a datos a servidores externos | Funciona **completamente offline** en red interna |
| No cita fuentes | Indica exactamente de quÃ© documento viene cada respuesta |
| Sin control de seguridad especÃ­fico | Detecta y bloquea intentos de manipulaciÃ³n |
| Base de conocimiento fija | Se actualiza automÃ¡ticamente al agregar nuevos PDFs |

---

## ğŸ” Por QuÃ© Es una SoluciÃ³n Profesional y Segura

**Privacidad garantizada:** El sistema corre 100% dentro de la infraestructura propia. NingÃºn dato, pregunta ni documento sale de la red corporativa. Es apto para entornos con restricciones de confidencialidad o cumplimiento normativo (GDPR, ISO 27001, etc.).

**Confiabilidad de las respuestas:** El modo estricto impide que el modelo genere contenido fuera de los documentos cargados. Cada respuesta viene acompaÃ±ada de su fuente, lo que permite auditar y verificar la informaciÃ³n en segundos.

**Seguridad activa:** El sistema incluye un validador con doble capa de protecciÃ³n contra intentos de manipulaciÃ³n (*prompt injection*), un riesgo real en sistemas de IA expuestos a usuarios finales.

**Mantenibilidad a largo plazo:** La arquitectura modular basada en principios SOLID significa que agregar un nuevo tipo de documento, cambiar el modelo de IA o migrar la base de datos vectorial son tareas de horas, no de semanas. Los 290+ tests automatizados garantizan que cada cambio no rompe el comportamiento existente.

**AutonomÃ­a tecnolÃ³gica:** Al usar modelos de cÃ³digo abierto (Ollama + HuggingFace), la empresa no depende de ningÃºn proveedor externo, no paga por consulta y puede cambiar de modelo cuando aparezca una mejor alternativa, sin tocar el resto del sistema.

---

## âœ¨ CaracterÃ­sticas

### ğŸ¯ RAG (Retrieval-Augmented Generation)
- **Modo estricto**: Solo responde con informaciÃ³n de documentos
- **RecuperaciÃ³n semÃ¡ntica**: Encuentra documentos relevantes por significado, no solo palabras clave
- **CitaciÃ³n de fuentes**: Muestra de quÃ© documento viene cada respuesta
- **Control de relevancia**: Configurable con threshold de similitud

### ğŸ”’ Seguridad
- **ValidaciÃ³n de queries**: Detecta 44+ palabras clave maliciosas
- **Filtros regex**: 7 patrones para detectar inyecciones
- **LÃ­mite de longitud**: ProtecciÃ³n contra queries excesivamente largas
- **Modo estricto RAG**: Previene "jailbreaking"

### ğŸ§  Embeddings Inteligentes
- **Factory Pattern**: Soporte para mÃºltiples proveedores
- **HuggingFace E5**: Embeddings multilingÃ¼es de alta calidad
- **Dummy Provider**: Para testing sin dependencias pesadas
- **FÃ¡cil extensiÃ³n**: Agrega nuevos proveedores sin modificar cÃ³digo

### ğŸ’¾ Vector Store
- **ChromaDB**: Persistencia en disco (recomendado producciÃ³n)
- **InMemory**: RÃ¡pido para desarrollo y testing
- **Factory Pattern**: Cambia entre stores sin tocar cÃ³digo

### ğŸ”§ Modularidad
- **ConfiguraciÃ³n centralizada**: Todo en `.env` o `settings.py`
- **Type hints completos**: Type safety con mypy
- **Logging estructurado**: Debug fÃ¡cil
- **Testing exhaustivo**: 296+ tests con pytest

### ğŸŒ LLM Local
- **Ollama**: Modelos LLM corriendo localmente
- **Soporte GPU**: NVIDIA CUDA para inferencia rÃ¡pida
- **MÃºltiples modelos**: llama3.2, phi, mistral, codellama

---

## ğŸ” CÃ³mo Funciona

### Flujo de Trabajo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     1. INGESTA DE DOCUMENTOS                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼                               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Cargar PDFs     â”‚            â”‚  Extraer Texto   â”‚
    â”‚  (pdfplumber)    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  (metadata)      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â–¼                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Chunking        â”‚         â”‚  Embeddings      â”‚
                    â”‚  (1000 chars)    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  (E5 384-dim)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          â”‚
                                                          â–¼
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                              â”‚  Vector Store        â”‚
                                              â”‚  (ChromaDB/Memory)   â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     2. QUERY (PREGUNTA DEL USUARIO)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼                               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ValidaciÃ³n      â”‚            â”‚  Embedding       â”‚
    â”‚  Seguridad       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  de Query        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â–¼                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  BÃºsqueda        â”‚         â”‚  Filtro por      â”‚
                    â”‚  Similitud       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Relevancia      â”‚
                    â”‚  (cosine)        â”‚         â”‚  (min_score)     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          â”‚
                                                          â–¼
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                              â”‚  Top K Documentos    â”‚
                                              â”‚  MÃ¡s Relevantes      â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     3. GENERACIÃ“N DE RESPUESTA                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼                               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Formatear       â”‚            â”‚  Prompt con      â”‚
    â”‚  Contexto        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Contexto        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â–¼                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Enviar a LLM    â”‚         â”‚  Generar         â”‚
                    â”‚  (Ollama)        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Respuesta       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          â”‚
                                                          â–¼
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                              â”‚  Respuesta +         â”‚
                                              â”‚  Fuentes Citadas     â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Ejemplo PrÃ¡ctico

1. **Usuario pregunta**: "Â¿CuÃ¡l es el horario de atenciÃ³n?"

2. **Sistema busca** en documentos usando embeddings semÃ¡nticos

3. **Encuentra chunks relevantes**:
   ```
   Documento: FAQ.pdf, PÃ¡gina 3
   Texto: "Nuestro horario de atenciÃ³n es de Lunes a Viernes..."
   Relevancia: 0.87
   ```

4. **Genera respuesta**:
   ```
   El horario de atenciÃ³n es de Lunes a Viernes de 9:00 a 18:00 horas.
   
   Fuente: FAQ.pdf, pÃ¡gina 3
   ```

---

## ğŸ—ï¸ Arquitectura

### Diagrama de Componentes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                    â”‚
â”‚                          MAIN APPLICATION                          â”‚
â”‚                                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                          â”‚                          â”‚
        â–¼                          â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   INGESTION   â”‚         â”‚   RETRIEVAL   â”‚         â”‚     CHAT      â”‚
â”‚   PIPELINE    â”‚         â”‚   SYSTEM      â”‚         â”‚    SERVICE    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                          â”‚                          â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                          â”‚
        â–¼             â–¼            â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Document   â”‚ â”‚Embeddingsâ”‚ â”‚  Vector  â”‚         â”‚   LLM Client     â”‚
â”‚  Processor  â”‚ â”‚ Provider â”‚ â”‚  Store   â”‚         â”‚   (Ollama)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚            â”‚                          â”‚
        â–¼             â–¼            â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Chunking  â”‚ â”‚ HF E5 /  â”‚ â”‚ ChromaDB â”‚         â”‚  Security        â”‚
â”‚   Strategy  â”‚ â”‚  Dummy   â”‚ â”‚ / Memory â”‚         â”‚  Validator       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Patrones de DiseÃ±o Implementados

- **Factory Pattern**: CreaciÃ³n de embeddings y vector stores
- **Strategy Pattern**: Diferentes proveedores de embeddings
- **Repository Pattern**: AbstracciÃ³n de vector store
- **Dependency Injection**: ConfiguraciÃ³n centralizada

---

## ğŸ› ï¸ TecnologÃ­as

### Core
- **Python 3.12** - Lenguaje principal
- **Pydantic 2.12** - ValidaciÃ³n y configuraciÃ³n
- **python-dotenv** - Variables de entorno

### LLM & Embeddings
- **Ollama 0.1.x** - Servidor LLM local
- **HuggingFace Transformers 5.1** - Modelos de embeddings
- **PyTorch 2.10** - Backend para embeddings
- **sentence-transformers** - E5 multilingual embeddings

### Vector Database
- **ChromaDB 1.5** - Vector store persistente
- **numpy 2.4** - Operaciones vectoriales

### Document Processing
- **pdfplumber 0.11** - ExtracciÃ³n de PDFs
- **PyPDF2 3.0** - Procesamiento de PDFs

### Testing & Quality
- **pytest 9.0** - Framework de testing
- **mypy 1.19** - Type checking
- **coverage** - Cobertura de tests

### Docker
- **Docker 20.10+** - ContainerizaciÃ³n
- **Docker Compose 2.0+** - OrquestaciÃ³n

---

## ğŸ“¦ Requisitos

### Requisitos del Sistema

#### InstalaciÃ³n Local
- **Python**: 3.12 o superior
- **RAM**: MÃ­nimo 8GB (recomendado 16GB)
- **Disco**: 10GB libres (para modelos)
- **GPU**: Opcional pero recomendada (NVIDIA con CUDA)
- **OS**: Windows 10/11, Linux, macOS

#### Docker
- **Docker**: 20.10+
- **Docker Compose**: 2.0+
- **RAM**: MÃ­nimo 8GB
- **Disco**: 15GB libres

### Dependencias Python

Ver `requirements.txt` para lista completa. Principales:
```
ollama>=0.1.0
transformers>=5.0.0
torch>=2.10.0
chromadb>=1.5.0
pydantic>=2.12.0
pydantic-settings>=2.7.0
pytest>=9.0.0
```

### Ollama

Necesitas Ollama instalado y corriendo:

**Linux/Mac:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
ollama serve  # Inicia el servidor
ollama pull llama3.2  # Descarga modelo
```

**Windows:**
```powershell
# Descargar desde: https://ollama.com/download
# Instalar e iniciar desde el menÃº
```

---

## ğŸš€ InstalaciÃ³n

### OpciÃ³n 1: InstalaciÃ³n Local (Desarrollo)

#### 1. Clonar el Repositorio

```bash
git clone https://github.com/LeandroTombe/chatbotproyectof.git
cd chatbotproyectof
```

#### 2. Crear Entorno Virtual

**Linux/Mac:**
```bash
python3.12 -m venv .venv
source .venv/bin/activate
```

**Windows:**
```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
```

#### 3. Instalar Dependencias

```bash
# Actualizar pip
pip install --upgrade pip

# Instalar dependencias
pip install -r requirements.txt
```

#### 4. Configurar Ollama

```bash
# Verificar que Ollama estÃ© corriendo
ollama list

# Descargar modelo (primera vez)
ollama pull llama3.2

# Verificar
ollama list
```

#### 5. Configurar Variables de Entorno

```bash
# Copiar template
cp .env.example .env

# Editar .env con tu editor favorito
nano .env  # o code .env, vim .env, etc.
```

ConfiguraciÃ³n mÃ­nima en `.env`:
```bash
OLLAMA_MODEL=llama3.2
EMBEDDING_PROVIDER=hf-e5
EMBEDDING_MODEL=intfloat/multilingual-e5-small
EMBEDDING_DIMENSION=384
VECTOR_STORE_TYPE=chroma
```

#### 6. Preparar Documentos

La carpeta `data/pdfs/` ya existe en el proyecto. Simplemente copiÃ¡ tus PDFs ahÃ­:

```bash
# Copiar tus PDFs a data/pdfs/
cp /ruta/a/tus/pdfs/*.pdf data/pdfs/
```

```powershell
# Windows
Copy-Item "C:\ruta\a\tus\pdfs\*.pdf" "data\pdfs\"
```

> Al iniciar la aplicaciÃ³n, los documentos se indexan automÃ¡ticamente. No hace falta ningÃºn paso adicional.

#### 7. Â¡Listo para Usar!

```bash
python main.py
```

### OpciÃ³n 2: Docker (ProducciÃ³n/Testing)

Ver [secciÃ³n Docker](#-docker) mÃ¡s abajo o consultar [README.docker.md](README.docker.md).

**Quick Start:**
```powershell
# Windows
.\scripts\docker-setup.ps1

# Linux/Mac
chmod +x scripts/docker-setup.sh
./scripts/docker-setup.sh
```

---

## âš™ï¸ ConfiguraciÃ³n

### Archivo .env

El proyecto usa variables de entorno para configuraciÃ³n. Ejemplo completo:

```bash
# ========================================
# Ollama LLM Configuration
# ========================================
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
OLLAMA_TIMEOUT=180
OLLAMA_MAX_TOKENS=300
OLLAMA_TEMPERATURE=0.7

# ========================================
# RAG Configuration
# ========================================
RAG_TOP_K=2                      # Documentos a recuperar
RAG_MIN_RELEVANCE=0.3            # Score mÃ­nimo (0-1)
RAG_MAX_CONTEXT_LENGTH=1000      # Caracteres mÃ¡ximos
RAG_INCLUDE_SOURCES=True         # Incluir fuentes en respuesta
RAG_STRICT_MODE=True             # Solo responder con docs
RAG_ENABLE_SECURITY=True         # ValidaciÃ³n de seguridad

# ========================================
# Embeddings Configuration
# ========================================
EMBEDDING_PROVIDER=hf-e5
EMBEDDING_MODEL=intfloat/multilingual-e5-small
EMBEDDING_DIMENSION=384
EMBEDDING_BATCH_SIZE=32

# Alternativa: Dummy (para testing)
# EMBEDDING_PROVIDER=dummy
# EMBEDDING_MODEL=dummy-embeddings
# EMBEDDING_DIMENSION=768

# ========================================
# Chunking Configuration
# ========================================
CHUNK_SIZE=1000                  # TamaÃ±o de chunks
CHUNK_OVERLAP=200                # Overlap entre chunks
CHUNK_SEPARATOR=\n\n             # Separador de chunks

# ========================================
# Vector Store Configuration
# ========================================
VECTOR_STORE_TYPE=chroma         # chroma o memory
CHROMA_PERSIST_DIRECTORY=./vectorstore_data
CHROMA_COLLECTION_NAME=documents
```

### Modelos Disponibles

#### Ollama (LLM)
```bash
# PequeÃ±os y rÃ¡pidos
ollama pull phi              # 1.3GB
ollama pull llama3.2         # 2GB (recomendado)

# Modelos grandes (mejor calidad)
ollama pull mistral          # 4GB
ollama pull llama2           # 4GB
ollama pull codellama        # 4GB
```

#### HuggingFace (Embeddings)
```python
# En .env, cambiar EMBEDDING_MODEL:

# PequeÃ±o y rÃ¡pido (recomendado)
intfloat/multilingual-e5-small     # 384 dim

# Mejor calidad
intfloat/multilingual-e5-base      # 768 dim
intfloat/multilingual-e5-large     # 1024 dim
```

---

## ğŸ’» Uso

### Comando Principal

```bash
# Ejecutar aplicaciÃ³n principal
python main.py
```

### Flujo de Uso

1. **Al iniciar**, el sistema:
   - Carga configuraciÃ³n
   - Inicializa embeddings
   - Crea/conecta vector store
   - Configura LLM client

2. **Carga documentos** (si es primera vez):
   - Lee PDFs de `./documents/`
   - Extrae y divide texto en chunks
   - Genera embeddings
   - Almacena en vector store

3. **Chat interactivo**:
   ```
   Usuario: Â¿CuÃ¡l es el horario de atenciÃ³n?
   Bot: El horario de atenciÃ³n es...
        Fuente: FAQ.pdf, pÃ¡gina 3
   
   Usuario: Â¿Aceptan tarjetas?
   Bot: SÃ­, aceptamos Visa, Mastercard...
        Fuente: Pagos.pdf, pÃ¡gina 1
   ```

4. **Comandos especiales**:
   - `salir`, `exit`, `quit` - Terminar
   - `stats` - Ver estadÃ­sticas del vector store
   - `clear` - Limpiar conversaciÃ³n

### Ejemplos de Uso

#### Ejemplo 1: Primera EjecuciÃ³n

```bash
$ python main.py

================================================================================
  SETTING UP RAG SYSTEM COMPONENTS
================================================================================

âœ“ Embedder: HFMultilingualE5Embedding(...) (provider: hf-e5)
âœ“ Vector Store: Chroma
   Collection: documents
   Directory: ./vectorstore_data
âœ“ Chunker: chunk_size=1000, overlap=200
âœ“ Document Processor initialized
âœ“ Retriever: top_k=2, min_score=0.3
âœ“ Ingestion Pipeline initialized

================================================================================
  LOADING DOCUMENTS
================================================================================

Processing: FAQ.pdf
  âœ“ 5 chunks created
Processing: Manual.pdf
  âœ“ 12 chunks created
  
Total documents processed: 2
Total chunks stored: 17

================================================================================
  CHATBOT RAG - INTERACTIVE MODE
================================================================================

Bot: Â¡Hola! PregÃºntame sobre los documentos cargados.
Usuario> Â¿QuÃ© documentos tienes?
Bot: Tengo acceso a los siguientes documentos:
     - FAQ.pdf
     - Manual.pdf
```

#### Ejemplo 2: Testing RÃ¡pido

```bash
# Usar dummy embeddings (sin descargar modelos)
export EMBEDDING_PROVIDER=dummy
export VECTOR_STORE_TYPE=memory

python main.py
```

#### Ejemplo 3: Solo Procesar Documentos

```python
# script personalizado
from ingestion.pipeline import IngestionPipeline

pipeline = IngestionPipeline(processor, retriever)
pipeline.ingest_directory("./documents")
```

### Scripts Ãštiles

```bash
# Ver logs
tail -f logs/chatbot.log

# Limpiar vector store
rm -rf vectorstore_data/

# Limpiar cache de HuggingFace
rm -rf models/

# Ejecutar con debug
PYTHONPATH=. python -m pdb main.py
```

---

## ğŸ³ Docker

### Quick Start Docker

#### Windows (PowerShell)
```powershell
# Setup automÃ¡tico completo
.\scripts\docker-setup.ps1

# O manual:
Copy-Item .env.docker .env
docker-compose up -d --build
docker-compose exec ollama ollama pull llama3.2
docker-compose exec chatbot python main.py
```

#### Linux/Mac
```bash
# Setup automÃ¡tico completo
chmod +x scripts/docker-setup.sh
./scripts/docker-setup.sh

# O con Make:
make setup
```

### Comandos Docker

```bash
# Ver logs
docker-compose logs -f

# Ejecutar chatbot
docker-compose exec chatbot python main.py

# Ejecutar tests
docker-compose run --rm chatbot python -m pytest

# Shell interactivo
docker-compose exec chatbot bash

# Detener
docker-compose down

# Limpiar TODO
docker-compose down -v
```



## ğŸ“‚ Estructura del Proyecto

```
ChatBotProyecto/
â”‚
â”œâ”€â”€ ğŸ“„ main.py                  # Punto de entrada principal
â”œâ”€â”€ ğŸ“„ requirements.txt         # Dependencias Python
â”œâ”€â”€ ğŸ“„ .env.example            # Template de configuraciÃ³n
â”œâ”€â”€ ğŸ“„ mypy.ini                # ConfiguraciÃ³n type checking
â”‚
â”œâ”€â”€ ğŸ“ api/                    # (Futuro) API REST
â”‚
â”œâ”€â”€ ğŸ“ chat/                   # Sistema de chat
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py              # Modelos: Message, ChatResponse
â”‚   â”œâ”€â”€ rag_service.py         # Servicio RAG principal
â”‚   â”œâ”€â”€ security.py            # ValidaciÃ³n y seguridad
â”‚   â””â”€â”€ llm_clients/           # Clientes LLM
â”‚       â”œâ”€â”€ base.py            # Clase base abstracta
â”‚       â””â”€â”€ ollama_client.py   # ImplementaciÃ³n Ollama
â”‚
â”œâ”€â”€ ğŸ“ config/                 # ConfiguraciÃ³n
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py            # Settings con Pydantic
â”‚
â”œâ”€â”€ ğŸ“ core/                   # Core utilities
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ config.py              # ConfiguraciÃ³n legacy
â”‚
â”œâ”€â”€ ğŸ“ documents/              # Procesamiento de documentos
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ loaders/               # Loaders por tipo
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â””â”€â”€ pdf_loader.py
â”‚   â”œâ”€â”€ processor.py           # Procesador principal
â”‚   â””â”€â”€ factory.py             # Factory de loaders
â”‚
â”œâ”€â”€ ğŸ“ domain/                 # Modelos de dominio
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ models.py              # Chunk, SearchResult, etc.
â”‚
â”œâ”€â”€ ğŸ“ embeddings/             # Sistema de embeddings
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                # BaseEmbedding, DummyEmbedding
â”‚   â”œâ”€â”€ factory.py             # Factory pattern
â”‚   â””â”€â”€ providers/
â”‚       â””â”€â”€ hf_e5_embedding.py # HuggingFace E5
â”‚
â”œâ”€â”€ ğŸ“ ingestion/              # Pipeline de ingesta
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pipeline.py            # IngestionPipeline
â”‚   â””â”€â”€ pdf_loader.py          # Loader de PDFs
â”‚
â”œâ”€â”€ ğŸ“ processing/             # Procesamiento de texto
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ chunking.py            # TextChunker
â”‚
â”œâ”€â”€ ğŸ“ retrieval/              # Sistema de recuperaciÃ³n
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ retriever.py           # DocumentRetriever
â”‚
â”œâ”€â”€ ğŸ“ vectorstore/            # Vector stores
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                # BaseVectorStore, InMemory
â”‚   â”œâ”€â”€ factory.py             # Factory pattern
â”‚   â””â”€â”€ implementations/
â”‚       â””â”€â”€ chroma.py          # ChromaDB implementation
â”‚
â”œâ”€â”€ ğŸ“ tests/                  # Tests (296+ tests)
â”‚   â”œâ”€â”€ test_*.py              # Unit tests
â”‚   â”œâ”€â”€ providers/             # Tests de providers
â”‚   â””â”€â”€ compare/               # ComparaciÃ³n de embeddings
â”‚
â”œâ”€â”€ ğŸ“ docs/                   # DocumentaciÃ³n
â”‚   â”œâ”€â”€ FACTORY_PATTERN.md     # ExplicaciÃ³n Factory Pattern
â”‚   â”œâ”€â”€ ANALISIS_MEJORAS.md    # AnÃ¡lisis de cÃ³digo
â”‚   â””â”€â”€ GUIA_IMPLEMENTACION_MEJORAS.md
â”‚
â”œâ”€â”€ ğŸ“ scripts/                # Scripts de automatizaciÃ³n
â”‚   â”œâ”€â”€ docker-setup.sh        # Setup Docker (Linux/Mac)
â”‚   â”œâ”€â”€ docker-setup.ps1       # Setup Docker (Windows)
â”‚   â”œâ”€â”€ docker-cleanup.sh      # Cleanup (Linux/Mac)
â”‚   â””â”€â”€ docker-cleanup.ps1     # Cleanup (Windows)
â”‚
â”œâ”€â”€ ğŸ“ data/                   # Datos procesados (git ignored)
â”œâ”€â”€ ğŸ“ logs/                   # Logs de aplicaciÃ³n (git ignored)
â”œâ”€â”€ ğŸ“ models/                 # Cache de modelos HF (git ignored)
â”œâ”€â”€ ğŸ“ documents/              # PDFs fuente (git ignored)
â””â”€â”€ ğŸ“ vectorstore_data/       # ChromaDB data (git ignored)
â”‚
â”œâ”€â”€ ğŸ³ Docker Files
â”œâ”€â”€ Dockerfile                 # Imagen de la aplicaciÃ³n
â”œâ”€â”€ docker-compose.yml         # OrquestaciÃ³n de servicios
â”œâ”€â”€ .dockerignore             # Exclusiones de build
â”œâ”€â”€ .env.docker               # Template variables Docker
â”‚
â”œâ”€â”€ ğŸ“š DocumentaciÃ³n Docker
â”œâ”€â”€ README.docker.md          # GuÃ­a completa Docker
â”œâ”€â”€ README.docker.windows.md  # GuÃ­a Windows especÃ­fica
â”œâ”€â”€ DOCKER_QUICKSTART.md      # Referencia rÃ¡pida
â”‚
â””â”€â”€ ğŸ”§ Otros
    â”œâ”€â”€ Makefile              # Comandos simplificados (Linux/Mac)
    â”œâ”€â”€ .gitignore           # Exclusiones de Git
    â””â”€â”€ mypy.ini             # ConfiguraciÃ³n mypy
```

---

## ğŸ§ª Testing

### Ejecutar Tests

```bash
# Todos los tests
python -m pytest

# Con verbose
python -m pytest -v

# Con coverage
python -m pytest --cov=. --cov-report=html

# Tests especÃ­ficos
python -m pytest tests/test_embeddings.py
python -m pytest tests/test_vectorstore.py
python -m pytest tests/test_rag_service.py

# Solo tests rÃ¡pidos (excluir HF que requiere torch)
python -m pytest --ignore=tests/providers/

# Ver coverage HTML
# Abre htmlcov/index.html en tu navegador
```

### EstadÃ­sticas de Testing

```
ğŸ“Š Coverage Actual:
- 296 tests pasando
- 41 tests de embeddings
- 48 tests de vector store
- 9 tests de factory patterns
- + tests de RAG, seguridad, retrieval, etc.
```

### Tests en Docker

```bash
# Ejecutar todos los tests
docker-compose run --rm chatbot python -m pytest

# Con coverage
docker-compose run --rm chatbot python -m pytest --cov=. --cov-report=html
```

---

## ğŸ“š DocumentaciÃ³n Adicional


### Recursos Externos

- **Ollama**: https://ollama.ai/
- **ChromaDB**: https://docs.trychroma.com/
- **HuggingFace Transformers**: https://huggingface.co/docs/transformers/
- **Pydantic**: https://docs.pydantic.dev/
- **Docker**: https://docs.docker.com/

---

## ğŸ¤ ContribuciÃ³n

### CÃ³mo Contribuir

1. **Fork** el repositorio
2. **Crea** una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. **Commit** tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. **Push** a la rama (`git push origin feature/AmazingFeature`)
5. **Abre** un Pull Request

### GuÃ­as de Desarrollo

- Usa **type hints** en todo el cÃ³digo
- Escribe **tests** para nuevas funcionalidades
- Actualiza la **documentaciÃ³n**
- Sigue **PEP 8** (usa `black` para formatear)
- Ejecuta **mypy** para type checking
- MantÃ©n coverage de tests > 80%

### Reportar Bugs

Abre un issue con:
- DescripciÃ³n del problema
- Pasos para reproducir
- Comportamiento esperado vs actual
- Logs relevantes
- VersiÃ³n de Python, OS, etc.


---

## ğŸ‘¨â€ğŸ’» Autor

**Leandro Tombe**
- GitHub: [@LeandroTombe](https://github.com/LeandroTombe)
- Repositorio: [chatbotproyectof](https://github.com/LeandroTombe/chatbotproyectof)

---

## ğŸ™ Agradecimientos

- **Ollama** - Por facilitar LLMs locales
- **ChromaDB** - Por un excelente vector database
- **HuggingFace** - Por modelos de embeddings de calidad
- **Comunidad Python** - Por las increÃ­bles librerÃ­as

---

## ğŸ“ Soporte

Â¿Necesitas ayuda?

1. ğŸ“– Revisa la [documentaciÃ³n](#-documentaciÃ³n-adicional)
2. ğŸ› Busca en [Issues](https://github.com/LeandroTombe/chatbotproyectof/issues)
3. ğŸ’¬ Abre un nuevo Issue
4. ğŸ“§ Contacta al autor

---

<div align="center">

**â­ Si te gusta este proyecto, considera darle una estrella en GitHub â­**

Hecho con â¤ï¸ usando Python, Ollama y mucho â˜•

</div>

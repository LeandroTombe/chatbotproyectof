# ============================================================================
# Environment Variables for Docker Deployment
# Copy this file to .env and adjust values as needed
# ============================================================================

# ========================================
# Ollama LLM Configuration
# ========================================
OLLAMA_MODEL=llama3.2
OLLAMA_TIMEOUT=180
OLLAMA_MAX_TOKENS=300
OLLAMA_TEMPERATURE=0.7

# Available models (download required):
# - llama3.2 (recommended, 2GB)
# - phi (1.3GB)
# - mistral (4GB)
# - codellama (4GB)

# ========================================
# RAG Configuration
# ========================================
RAG_TOP_K=2
RAG_MIN_RELEVANCE=0.3
RAG_MAX_CONTEXT_LENGTH=1000
RAG_INCLUDE_SOURCES=True
RAG_STRICT_MODE=True
RAG_ENABLE_SECURITY=True

# ========================================
# Embeddings Configuration
# ========================================
EMBEDDING_PROVIDER=hf-e5
EMBEDDING_MODEL=intfloat/multilingual-e5-small
EMBEDDING_DIMENSION=384

# Alternative providers:
# - dummy (for testing)
# EMBEDDING_PROVIDER=dummy
# EMBEDDING_MODEL=dummy-embeddings
# EMBEDDING_DIMENSION=768

# ========================================
# Chunking Configuration
# ========================================
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
CHUNK_SEPARATOR=\n\n

# ========================================
# Vector Store Configuration
# ========================================
VECTOR_STORE_TYPE=chroma

# Options:
# - memory (no persistence, faster)
# - chroma (persistent, recommended for production)
